#!/bin/bash

## Generate command-line arguments for elastix using 'Full' ImageSampler
regid="$(basename "${BASH_SOURCE/.gen}")"
parcsv="$(dirname "$BASH_SOURCE")/$regid.csv"

# attention: must be in single quotes; each column entry must be '$name'
cfgrow='$cfgid,$usemsk,$interp,$pyramid,$optim,$cgtype,$sim,$bins,$levels,$iters,$steps,$step,$epsilon,$alpha,$A,$a,$ds,$be'

# initial/constant parameter values
set_defaults()
{
  # general parameters
  usemsk=true                        # whether to use foreground masks
  interp='Linear'                    # Linear, BSpline
  pyramid='Recursive'                # Recursive, Smoothing, Shrinking
  optim='ConjugateGradient'          # StandardGradientDescent, ConjugateGradient, ConjugateGradientFRPR
  sim='NormalizedMutualInformation'  # NormalizedMutualInformation, AdvancedMattesMutualInformation
  bins=64                            # 16, 32, 64
  levels=4                           # 3, 4
  iters=100                          # StandardGradientDescent: 100-500; ConjugateGradient: ~100
  # ConjugateGradient specific parameters
  cgtype='PolakRibiere'
  steps=20
  step='4.0 2.0 1.0 0.5'
  epsilon=1e-05  # i.e., ValueTolerance
  # StandardGradientDescent specific paramaters
  alpha=0.6
  A=20
  a=1000
  # transformation model parameters
  ds=2.5
  be=1
}

# auxiliary function to append row with parameter values
append_row()
{
  let i++
  local cfgid=$(printf %04d $i)
  eval "echo \"$cfgrow\"" >> "$parcsv"
}

# write header and initialize row counter
echo "${cfgrow//$}" > "$parcsv"
i=0

# ------------------------------------------------------------------------------
# Initial parameter exploration using conjugate gradient descent

# 1) control point spacing and bending energy weight
set_defaults
optim='ConjugateGradient'
iters=100
for ds in 2.5 5.0; do
  for be in 0 0.0001 0.0005 0.001 0.005 0.01 0.05 0.1 0.2 0.5; do
    append_row
  done
done

# Comment following line when previous tests are done, and the results have been analyzed.
# Adjust parameters for following tests to more narrow ranges found to perform well.
exit 0

# try even larger bending energy weights
#
# Surprisingly, results with ALBERTs dataset were best for bending energy weight 0.5, i.e.,
# the highest weight value explored so far.
#
# Bending energy weights larger than the weight of the image similarity term appear to be not uncommon.
# Found values being used of 0.1 (par0025: mouse brain), 0.3, 5, 20 (par0020: rat brain), and an even
# quantitatively optimized weight of up to 50 (par0023: head/neck).
for ds in 2.5 5.0; do
  for be in 0.8 1.0 1.2 1.4; do
    append_row
  done
done
for ds in 2.5 5.0; do
  for be in 1.6 1.8 2.0 2.2 2.4 2.6 2.8 3.0; do
    append_row
  done
done

# Comment following line when previous tests are done, and the results have been analyzed.
# Adjust parameters for following tests to more narrow ranges found to perform well.
exit 0

# ------------------------------------------------------------------------------
# Compare to standard gradient descent on which stochastic gradient descent is based
# (here using all image samples, however, no stochastic gradient descent)
optim='StandardGradientDescent'
ds=5.0
for be in 0.5 1 1.5; do
  for A in 20 50; do
    for a in 1000 5000 10000 50000 100000 500000; do
      for iters in 100 300 500; do
        append_row
      done
    done
  done
done
