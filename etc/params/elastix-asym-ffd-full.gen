#!/bin/bash

## Generate command-line arguments for elastix using 'Full' ImageSampler
regid="$(basename "$BASH_SOURCE")"
regid="${regid/.gen}"

# initial/constant parameter values
usemsk=false                       # whether to use foreground masks
interp='Linear'                    # Linear, BSpline
pyramid='Recursive'                # Recursive, Smoothing, Shrinking
optim='ConjugateGradient'          # StandardGradientDescent, ConjugateGradient, ConjugateGradientFRPR
sim='NormalizedMutualInformation'  # NormalizedMutualInformation, AdvancedMattesMutualInformation
bins=64                            # 16, 32, 64
levels=4                           # 3, 4
iters=100                          # StandardGradientDescent: 100-500; ConjugateGradient: ~100

# ConjugateGradient specific parameters
cgtype='PolakRibiere'
steps=20
step='4.0 2.0 1.0 0.5'
epsilon=1e-05  # i.e., ValueTolerance

# StandardGradientDescent specific paramaters
alpha=0.6
A=20
a=1000

# transformation model parameters
ds=2.5
be=1

# auxiliary function to append row with parameter values
# Attention: Always ensure that header and order of append_row values is consistent!
i=0
parcsv="$(dirname "$BASH_SOURCE")/$regid.csv"
echo "cfgid,usemsk,interp,pyramid,optim,cgtype,sim,bins,levels,iters,steps,step,epsilon,alpha,A,a,ds,be" > "$parcsv"

append_row()
{
  let i++
  local cfgid=$(printf %04d $i)
  echo "$cfgid,$usemsk,$interp,$pyramid,$optim,$cgtype,$sim,$bins,$levels,$iters,$steps,$step,$epsilon,$alpha,$A,$a,$ds,$be" >> "$parcsv"
}

# initial model parameter exploration using conjugate gradient descent with line search
optim='ConjugateGradient'
iters=100
for usemsk in false true; do
  for ds in 2.5 5.0; do
    for be in 0 0.0001 0.0005 0.001 0.005 0.01 0.05 0.1 0.2 0.5; do
      append_row
    done
  done
done

# try even larger bending energy weights
#
# Surprisingly, results with ALBERTs dataset were best for bending energy weight 0.5, i.e.,
# the highest weight value explored so far.
#
# Bending energy weights larger than the weight of the image similarity term appear to be not uncommon.
# Found values being used of 0.1 (par0025: mouse brain), 0.3, 5, 20 (par0020: rat brain), and an even
# quantitatively optimized weight of up to 50 (par0023: head/neck).
usemsk=true
for ds in 2.5 5.0; do
  for be in 0.8 1.0 1.2 1.4; do
    append_row
  done
done
for ds in 2.5 5.0; do
  for be in 1.6 1.8 2.0 2.2 2.4 2.6 2.8 3.0; do
    append_row
  done
done

# once initial parameter exploration done, try standard gradient descent
# with (more) informed control point spacing and bending energy weight choices
if [ 1 -eq 1 ]; then
  optim='StandardGradientDescent'
  ds=5.0
  for be in 0.5 1 1.5; do
    for A in 20 50; do
      for a in 1000 5000 10000 50000 100000 500000; do
        for iters in 100 300 500; do
          append_row
        done
      done
    done
  done
fi
