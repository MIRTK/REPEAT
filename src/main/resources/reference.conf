# ----------------------------------------------------------------------------------------------------------------------
# Auxiliary software tools
software {
  shared = true         # Whether software installations are shared between all compute nodes
                        # true:  Absolute paths of binaries are used to access the same binary
                        #        files on a shared network drive. If command names are given only
                        #        the software is expected to be available in the PATH on each node.
                        # false: Binary files used by a remote task are packed using CARE. The resulting
                        #        (self-extracting) archive is copied to the remote and extracted into
                        #        the working directory of the task.
  care       = care     # Local path of "care" executable used to pack binary files (http://reproducible.io/#downloads)
  care-tmp   = /tmp     # Temporary directory for creating archive files
  tar        = /bin/tar # Local path of "tar" executable used to create archive files
  repository = Bin      # Local directory containing pre-packed CARE archives
}
irtk {
  dir      = Bin     # Directory where the binary IRTK executables are located
  threads  = 1       # Maximum number of threads an IRTK binary may spawn (0: #cores)
  apply-nn = "${irtk.dir}/transformation <source> <out> -target <target> -dofin <phi> -nn -matchInputType"
  jacobian = "${irtk.dir}/jacobian <phi> <out>"
}

# ----------------------------------------------------------------------------------------------------------------------
# Task execution environment
environment {

  # Which environment to use for parallel and/or resource intensive tasks
  short = Local # Environment to use for short running jobs (<1hr)
  long  = Local # Environment to use for long running jobs (>=1hr)
  links = true  # Whether to use symbolic links to input/output files
  # Set this to true if all machines in the computing environment
  # have access to the same shared network drives on which the
  # input and output files are located to save unnecessary copying.
  nodes = 0     # Maximum number of parallel tasks when local environment is used (0: #cores)

  # SLURM configuration
  slurm {
    host = predict5.doc.ic.ac.uk
    user = as12312
    auth = id_dsa
    queue {
      short = short # Name of queue for short running jobs (<1hr)
      long  = long  # Name of queue for long running jobs (>=1hr)
    }
  }
}

# ----------------------------------------------------------------------------------------------------------------------
# Dataset used for evaluation
dataset {
  dir    = .    # Top-level directory (if any, otherwise specify individual paths)
  shared = true # Whether dataset directory is readable from all compute nodes
                # true:  Read input files directly from the dataset directory
                # false: For tasks executed on remote environment, copy input files to the workspace if it is
                #        shared between compute nodes or the working directory of the task otherwise
  # Structural MR images to be registered
  images {
    csv    = ${dataset.dir}/Info/Images.csv
    dir    = ${dataset.dir}/Images
    prefix = ""
    suffix = _3.nii.gz
  }
  # Corresponding (manual/semi-automatic) expert segmentations
  labels {
    csv    = ${dataset.dir}/Info/Labels.csv
    dir    = ${dataset.dir}/Labels
    prefix = ""
    suffix = _3_glm.nii.gz
  }
  # Reference image/template used for initial spatial normalization
  template {
    id    = mni305
    image = Config/${dataset.template.id}.nii.gz
  }
}

# ----------------------------------------------------------------------------------------------------------------------
# Directory used as workspace for output files
workspace {
  dir    = Workspace # Top-level directory of workspace
  shared = true # Whether workspace is shared among compute nodes
                # true:  Use workspace directory as common top-level directory of unpacked CARE archives
                #        All input files are copied to the common rootfs subdirectory
                # false: For tasks executed on remote environment, input/output files are copied to/from
                #        the remote working directory of the task
  # Copies of evaluation dataset files
  images.dir = images
  labels.dir = labels
  # Transformations computed by spatial normalization and pre-alignment workflows
  dofs {
    dir     = dofs
    rigid   = ${workspace.dofs.dir}/rigid
    initial = ${workspace.dofs.dir}/initial
    affine  = ${workspace.dofs.dir}/affine
    prefix  = ""
    suffix  = .dof.gz
  }
  # Results of each registration
  results {
    dir    = regs
    dofs   = ${workspace.results.dir}/dofs
    images = ${workspace.results.dir}/images
    labels = ${workspace.results.dir}/labels
  }
  # Settings for process output logging
  logs {
    dir    = logs
    suffix = .log
    append = false
    flush  = true
    tee    = true
  }
}

# ----------------------------------------------------------------------------------------------------------------------
# Registration tools
#
# registration {
#   <name> {
#     dof2aff  = Convert affine IRTK transformation to input transformation
#     command  = Registration command
#     phi2dof  = Convert output transformation to IRTK transformation
#     apply-nn = Transform label image using nearest neighbor interpolation
#     jacobian = Compute determinant of transformation Jacobian
#   }
# }
registration {
  ireg-ffd {
    command = ${irtk.dir}/ireg <target> <source> -model FFD -dofin <aff> -dofout <phi> <args>
    params  = Config/ireg-ffd.csv
  }
  ireg-svffd {
    command = ${irtk.dir}/ireg <target> <source> -model SVFFD -dofin <aff> -dofout <phi> <args>
    params  = Config/ireg-svffd.csv
    //params {
    //  ds  = [2.5]
    //  be  = [.0, .001, .005, .01, .05]
    //  im  = [FastSS, SS, RKE1, RK4]
    //  bch = [0, 4]
    //}
  }
  reg_f3d {
    aff-suffix = .txt
    phi-suffix = .nii.gz
    dof2aff    = ${irtk.dir}/dof2niftk <dofin> <aff>
    command    = reg_f3d -ref <target> -flo <source> -aff <aff> -cpp <phi>
    phi2dof    = ${irtk.dir}/niftk2dof <phi> <dofout>
    apply-nn   = ""
    jacobian   = ""
  }
}

# ----------------------------------------------------------------------------------------------------------------------
# Overlap measures
overlap {
  labels  = [Cortical, Non-Cortical, All]
  measure = [DSC, JSI]
}
